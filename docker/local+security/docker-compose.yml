---
version: '3.4'
services:

  # Identity Provider (OpenID Connect) for Web-SSO
  idp:
      build: 
        context: ./idp
        args:
          WEBAUTHN_PLUGIN_VERSION: "0.3.RELEASE"
      image: drivereu/keycloak:6.0.1-1
      hostname: iam.corp-demo.com
      volumes:
        - ./sample-ssl-clients/test-ca-crt.pem:/tmp/test-ca-crt.pem
        - ./idp/tls.crt:/etc/x509/https/tls.crt
        - ./idp/tls.key:/etc/x509/https/tls.key
        # - ./keycloak/themes/thales:/opt/jboss/keycloak/themes/thales
        # The realm must have been exported with instructions from: https://github.com/jboss-dockerfiles/keycloak/tree/master/server#exporting-a-realm
        # $ docker exec -it docker_keycloak_1 sh -c "keycloak/bin/standalone.sh -Djboss.socket.binding.port-offset=100 -Dkeycloak.migration.action=export -Dkeycloak.migration.provider=singleFile -Dkeycloak.migration.realmName=THALES -Dkeycloak.migration.usersExportStrategy=REALM_FILE -Dkeycloak.migration.file=/tmp/THALES-realm.json"
        # Currently, it is not possible to import the realm with WebauthnRegister in the Required Actions of the users, else error occurs:
        # "ERROR [org.keycloak.services.error.KeycloakErrorHandler] (default task-7) Uncaught server error: java.lang.IllegalArgumentException: No enum constant org.keycloak.models.UserModel.RequiredAction.WEBAUTHN-REGISTER"
        # - ./keycloak/driver-realm.json:/tmp/driver-realm.json
        
      environment:
        X509_CA_BUNDLE: /tmp/test-ca-crt.pem
        DB_VENDOR: h2
        KEYCLOAK_HOSTNAME: iam.corp-demo.com
        KEYCLOAK_USER: admin
        KEYCLOAK_PASSWORD: changeit
        
        # KEYCLOAK_IMPORT cannot be used here because refers to objects from Webauthn plugin which is deployed after attempt to import the realm from KEYCLOAK_IMPORT -> fail
        # Workaround: in the command script , use Admin CLI to import the realm after startup if not there yet
        # KEYCLOAK_IMPORT: /tmp/thales-realm.json
        # Use another variable for realm import after keycloak startup (see docker-entrypoint.sh)
        # KEYCLOAK_IMPORTED_REALM: /tmp/thales-realm.json

        # To add a custom theme extend the Keycloak image add the theme to the /opt/jboss/keycloak/themes directory.
        # KEYCLOAK_WELCOME_THEME: thales
        # KEYCLOAK_DEFAULT_THEME: thales
        # KEYCLOAK_LOGLEVEL: DEBUG
        # ROOT_LOGLEVEL: INFO
        # JDBC_PARAMS: "connectTimeout=30000"
      ports:
        - 8443:8443
      #depends_on:
      #  - mysql
      entrypoint: sh "/opt/jboss/tools/docker-entrypoint-override.sh" 
      command: ["-b", "0.0.0.0"]

  # Certificate Management Service
  cert_mgt:
    build: ./cert_mgt
    image: drivereu/cert_mgt:2.0.0
    hostname: certmgt
    ports:
     - "8442:8442"
     - "8443:8443"
     - "9090:8080"

  zookeeper:
    image: confluentinc/cp-zookeeper:5.0.0
    hostname: zookeeper
    ports:
     - "3500:3500"
    volumes:
     - ./zookeeper/config/zookeeper.properties:/etc/kafka/zookeeper.properties
     - ./zookeeper/config/zookeeper_jaas.conf:/etc/kafka/zookeeper_jaas.conf
    environment:
      KAFKA_OPTS: '-Djava.security.auth.login.config=/etc/kafka/zookeeper_jaas.conf'
      ZOOKEEPER_CLIENT_PORT: 3500
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:5.0.0
    hostname: broker
    depends_on:
      - zookeeper  
    ports:
      - "3501:3501"
    volumes:
      - ./broker/config/ssl:/etc/kafka/secrets
      # For debugging, create log4j.properties based on log4j.properties.orig in folder 'broker/config' and customize it.
      #      - ./broker/config/log4j.properties:/etc/kafka/log4j.properties   
    environment:
      # https://docs.confluent.io/current/installation/docker/docs/configuration.html#confluent-kafka-cp-kafka
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:3500'
      # The listener name must be 'PLAINTEXT' like the protocol name, as workaround for https://github.com/confluentinc/schema-registry/issues/648
      # SSL is enabled in Kafka Docker image only if KAFKA_ADVERTISED_LISTENERS has SSL://
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'SSL:SSL,PLAINTEXT:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'SSL://localhost:3501,PLAINTEXT://broker:9092'
      KAFKA_LISTENERS: 'SSL://0.0.0.0:3501,PLAINTEXT://0.0.0.0:9092'
      # KAFKA_SECURITY_INTER_BROKER_PROTOCOL: 'PLAINTEXT'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'SSL'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MESSAGE_MAX_BYTES: 100000000
      # KAFKA_REPLICA_FETCH_WAIT_MAX_MS: 10000
      KAFKA_REPLICA_FETCH_MAX_BYTES: 100000000
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: 'false'
      # Change log levels for debugging
      # More info: https://github.com/confluentinc/cp-docker-images/blob/master/debian/kafka/include/etc/confluent/docker/log4j.properties.template
      # KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka=INFO,org.apache.cxf=INFO,org.ow2.authzforce=INFO"
      # KAFKA_LOG4J_ROOT_LOGLEVEL: "INFO"
      # KAFKA_TOOLS_LOG4J_LOGLEVEL: "INFO"

      # SSL
      # See https://docs.confluent.io/current/installation/docker/docs/tutorials/clustered-deployment-ssl.html#id2 for docker image specifics, 
      # and https://docs.confluent.io/current/kafka/authentication_ssl.html in general
      # Uncomment line below for SSL debugging
      # KAFKA_OPTS: '-Djavax.net.debug=all'
      # PLAINTEXT protocol used by schema_registry and kafka_rest services. TODO: make them use SSL.
      # Name of file in /etc/kafka/secrets
      KAFKA_SSL_TRUSTSTORE_FILENAME: truststore.jks
      KAFKA_SSL_TRUSTSTORE_CREDENTIALS: truststore_creds
      # Name of file in /etc/kafka/secrets
      KAFKA_SSL_KEYSTORE_FILENAME: keystore.p12
      KAFKA_SSL_KEYSTORE_TYPE: PKCS12
      KAFKA_SSL_KEYSTORE_CREDENTIALS: keystore_creds
      KAFKA_SSL_KEY_CREDENTIALS: keystore_creds
      KAFKA_SSL_CLIENT_AUTH: required

  schema_registry:
    image: confluentinc/cp-schema-registry:5.0.0
    hostname: schema_registry
    depends_on:
      - zookeeper
      - broker
    ports:
      - "3502:3502"
    environment:
      # By default, ConsumerConfig 'fetch.max.wait.ms' = 500 triggering READ on <kafkastore.topic> ('_schemas' by default) via broker every 500 ms! Increase this value if you need to reduce network traffic or debug
      # ConsumerConfig properties, e.g. fetch.max.wait.ms can be set via SchemaRegistryConfig by prefixing with 'kafkastore.'
      SCHEMA_REGISTRY_KAFKASTORE_FETCH_MAX_WAIT_MS: 30000
      # SCHEMA_REGISTRY_LOG4J_LOGGERS: "kafka=TRACE"      
      SCHEMA_REGISTRY_HOST_NAME: schema_registry
      SCHEMA_REGISTRY_LISTENERS: 'http://0.0.0.0:3502'
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper:3500'
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://broker:9092'
      # SCHEMA_REGISTRY_KAFKASTORE_INIT_TIMEOUT_MS: 300000
      SCHEMA_REGISTRY_CUB_KAFKA_TIMEOUT: 300

  kafka_rest:
    image: confluentinc/cp-kafka-rest:5.0.0
    hostname: kafka_rest
    depends_on:
      - zookeeper
      - schema_registry
      - broker
    ports:
      - "8082:8082"
    environment:
      KAFKA_REST_HOST_NAME: kafka_rest
      KAFKA_REST_BOOTSTRAP_SERVERS: 'PLAINTEXT://broker:9092'
      KAFKA_REST_ZOOKEEPER_CONNECT: 'zookeeper:3500'
      KAFKA_REST_LISTENERS: 'http://0.0.0.0:8082'
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema_registry:3502'
      KAFKA_CONSUMER_REQUEST_TIMEOUT_MS: 30000
      KAFKA_REST_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,DELETE,OPTIONS'
      KAFKA_REST_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      KAFKA_REST_CUB_KAFKA_TIMEOUT: 300

  kafka_topics_ui:
    image: landoop/kafka-topics-ui:0.9.4
    hostname: kafka_topics_ui
    depends_on:
      - kafka_rest
    ports:
      - "3600:8000"
    environment:
      KAFKA_REST_PROXY_URL: 'http://kafka_rest:8082'
      PROXY: 'true'
      MAX_BYTES: 5000000
      RECORD_POLL_TIMEOUT: 10000

  kafka_schema_registry_ui:
    image: landoop/schema-registry-ui:0.9.5
    hostname: kafka_schema_registry_ui
    depends_on:
      - schema_registry
    ports:
      - "3601:8000"
    environment:
      SCHEMAREGISTRY_URL: 'http://schema_registry:3502'
      PROXY: 'true'
      
  postgres:
    image: postgres:9.6
    hostname: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: TRIAL_ADMIN
    volumes:
       - postgres-data:/var/lib/postgresql/data
    restart: unless-stopped
    
  admintool:
    image: drivereu/test-bed-admin:latest
    depends_on:
      - postgres
    ports:
      - "8090:8090"
    volumes:
      - ./admintool-config/gateways.json:/opt/application/config/gateways.json
      - ./admintool-config/solutions.json:/opt/application/config/solutions.json
      - ./admintool-config/topics.json:/opt/application/config/topics.json
      - ./admintool-config/standards.json:/opt/application/config/standards.json
    environment:
      KAFKA_BROKER_URL: broker:9092
      SCHEMA_REGISTRY_URL: http://schema_registry:3502
      zookeeper_host: zookeeper
      zookeeper_port: 3500
      schema_registry_url: http://schema_registry:3502
      testbed_secure_mode: 'true'
      testbed_init_auto: 'false'
      management_ca_cert_path: http://localhost:9090
      cert_handler_url: https://localhost:8443
      cert_pem_handler_url: https://localhost:8443
      security_rest_path_group: https://localhost:9443
      security_rest_path_topic: https://localhost:9443
      
  afteractionreview:
    image: drivereu/after-action-review:latest
    depends_on:
      - postgres
      - broker
      - schema_registry
    ports:
      - "8095:8095"
    environment:
      KAFKA_BROKER_URL: broker:9092
      SCHEMA_REGISTRY_URL: http://schema_registry:3502
      zookeeper_host: zookeeper
      zookeeper_port: 3500
      schema_registry_url: http://schema_registry:3502
  
  pgadmin:
    image: fenglc/pgadmin4
    depends_on:
      - postgres
    ports:
        - "5050:5050"
    restart: unless-stopped
      
volumes:
  postgres-data:
